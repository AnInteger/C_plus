## 			基于HUffman和LZ77的文件压缩

一、为什么做这个项目：

在学习了数据结构中的Huffman树之后，对Huffman编码比较敏感，了解到Huffman编码经常用于压缩，就萌生了去实现一个压缩算法的想法。最终以gzip压缩算法的大致思想实现了这个项目。

二、项目原理：

Huffman：

压缩：

1. 首先通过对文件的读取，进行信息统计。构建组织单元用来保存每一种字符的权值。
2. 以这些权值信息，通过优先级队列，从而构建Huffman树。
3. 先向新压缩文件中写入压缩文件的头部信息用于还原Huffman树
4. 通过对不同字符信息的编码从而减少其单独字符所占的字节数
5. 通过获取到的编码以位为单位写入到新的压缩文件中，从而实现压缩文件的目的

解压缩：

1. 通过在新的压缩文件中保存所有字符信息以及其权值，来还原Huffman树
2. 通过读取压缩文件的每一个字节的最高位来判断其编码对应的字符
3. 如果此时结点的左子树和右子树为空，表示此次匹配已经成功则开启下一个字符的匹配
4. 直到所有字符计数等于文件大小则证明解压缩完成

LZ77：

压缩：

1. 通过维护一个64k大小的窗口来实现其查找缓冲区和先行缓冲区的机制
2. 通过构建一个64k大小的哈希表来分别保存发生哈希冲突的字符和当前字符
3. 通过head中的值在prev对应的下标中存储发生哈希冲突的值达到映射的目的
4. 进行查找和哈希表插入时采用3个字节计算保证长度距离对小于原压缩串
5. 查找缓冲区进行查找当在先行缓冲区中发现重复字符串则向前进行查找并用长度距离对表示
6. 同时利用位图表明此时长度与原字符的区别以保证解压缩的识别
7. 滑动窗口保证每次所查询的最大范围为32k
8. 当先行缓冲区所剩数据小于临界值，为了避免上下文数据丢失，进行数据搬移
9. 同时搬移哈希表中的对应窗口，保证查询范围，知道压缩完毕

解压缩：

1.通过位图和压缩文件，如果是原字符则直接写入解压缩文件，如果不是则证明是长度距离对，同时读取3个字节获取到长度和距离

2.通过距离确定前文位置，然后依次读取长度个字符进行写入

三、项目问题

Huffman压缩

1. 如何构建一颗Huffman树？
2. 中文数据？
3. 如何获取字符编码？
4. 解压缩时如何确定'\n'字符的次数？
5. 如何还原Huffman树？
6. 解压缩Huffman树结点为空无法正常字符？

LZ77压缩

1. 查找缓冲区滑动，如何保证查找32k的范围？
2. 哈希表的空间多大？
3. 为什么MIN_LOOKAHEAD = MAX_MATCH + MIN_MATCH + 1？
5. 怎么判断是<长度，距离>对，还是原字符？
6. 先行缓冲区中数据不够怎么办？那么哈希表中数据怎么办？
7. 搬移条件，填充问题？
8. 解压缩长度距离对，需要刷新缓冲区？
8. 1个字节如何存储258的最大长度？

项目测试：

| 压缩文件类型 | 压缩文件大小 | LZ77压缩效率 | Huffman压缩效率 | 整体压缩效率 | LZ77压缩率 | Huffman压缩率 | 整体压缩率 |
| ------------ | ------------ | ------------ | --------------- | ------------ | ---------- | ------------- | :--------: |
| 中文txt      | 9.56M        | 3.28s        | 35.04s          | 29s          | 76%        | 77%           |    67%     |
| 英文txt      | 3.44M        | 2.54s        | 12.5s           | 8.3s         | 49%        | 57%           |    42%     |
| 图片jpg      | 1.5M         | 1.98s        | 6s              | 6.78s        | 112%       | 100%          |    106%    |
| 视频         | 3.54M        | 4.03s        | 14s             | 14.53s       | 100%       | 98%           |    94%     |
| 音乐         | 2.28M        | 1.13s        | 8s              | 9.98s        | 111%       | 101%          |    105%    |

效率问题：

1. 针对于文本格式的文件LZ77压缩时间和压缩率都高于Huffman压缩
2. 针对图片、视频、音乐压缩的效果十分不好

解决方案：

1. Huffman压缩：
   1. 通过优先级队列构建一个小堆，每次取堆顶的两个元素从而保证是当前权值中最小的，求和后，将这个二叉树在插进小堆中，最终这个小堆就只剩一个二叉树的根节点，此时这个根节点就是Huffman树的根节点
   2. 通过改变字符数据的类型，以无符号字符类型来解决中文字节问题
   3. 通过字符权值递归在Huffman树中查找，通过其父结点确认当前节点是左节点还是右结点，然后确定编码是'0'还是'1',然后回到其父结点向上遍历直到回到根节点，再进行编码逆置，得到最终当前字符的编码
   4. 如果出现连续'\n'时进行单独处理，访问其后面的数据。确定此时的'\n'是头部字符
   5. 通过读取压缩文件的头部文件，获取到每个通过末尾的'\n'确定每个字符的次数，从而通过每个字符出现的次数重构Huffman树
   6. 在解压缩时访问到文件末尾的文件指针FF，再去进行解压缩寻找对应字符时，可能会导致程序崩溃，所以在解压缩开始时需要再进行一次判断，当前的结点如果就是空指针，则退出重新回到根节点重新开始解码下一个字符

1. LZ77压缩：
   1. 当查找缓冲区的范围超过32k时，则使用当前开始匹配的位置下标减去最大匹配范围，从而使查找的起始位置到当前的位置始终保持在32k范围，在进行查找时，当查找的匹配的距离大于当前查找范围时，则停止。
   2. 因为每次哈希函数至少计算三个字节，一个字节有2^8种可能，所以公有2^24种可能，并且通过哈希函数算出来的哈希值一定是在0~32k内，所以哈希桶prev的范围为2^15，通过哈希函数尽可能的通过上一次的哈希值来计算下一次的哈希值，尽可能使3个字节都尽量参与计算，最终是15位的哈希地址，所以prev哈希桶为32k，然后先行缓冲区对应的哈希桶head也为32k
   3. 保证在先行缓冲区内至少满足最大匹配长度和最小匹配长度，以及至少满足有一个字节的匹配长度，以保证后续数据可以正常搬移
   4. 通过一个字节255位的位图来标记<长度，距离>对的信息，保证在最大匹配长度范围内对数据进行分类，如果是0表示原字符，如果是1表示是长度，则向后再读取两个字节的距离，进行数据的解码工作
   5. 当先行缓冲区中数据个数小于MIN_LOOKAHEAD时，则表明此时数据已经无法保证下一次的正常匹配，则进行数据的搬移，将当前WSIZE2中的32k数据搬移至WSIZE1中，然后先行缓冲区再读取32k数据，进行拼接，保证数据连续性。而哈希表则需要保证查找范围对应到查找缓冲区和先行缓冲区，如果哈希值大于WSIZE则进行搬移。从而实现哈希表和缓冲区的对应搬移。
   6. 在搬移时只需要将WSIZE2的数据拷贝到WSIZE1中，再从文件中读取32k填充到WSIZE2中
   7. 当解压缩连续重复的字符串时，匹配范围可能超过当前写入文件中字符范围，而导致解压缩错误，此时为了避免这种情况，应该持续刷新缓冲区，保证数据写入的实时性。
   8. 一个字节通过0~255，通过0用来记录3个字节，255用来记录258个字节。在统计距离时通过两个字节进行统计，在写入时则通过减3赋值给一个字节，保证不会越界，然后写入文件时用0代表3，从而表明3~258，在解压缩时依次对长度进行加3来获取长度对
2. 效率问题：
   1. LZ77压缩效率之所以高于Huffman编码压缩是因为，LZ77仅仅是减少了重复字符出现的次数，只需要对原有的文件进行操作。而Huffman编码压缩时因为需要组织大量的数据，进行Huffman树的构建，从而得到一个庞大的Huffman树，再通过Huffman树去获取编码，这样效率就会十分低。如果采用范式Huffman树，就只需要拿到每个字符编码的长度，这样就可以通过数组模拟出Huffman树并且不需要给出孩子域。
   2. 因为图片，音乐和视频的底层数据重复的概率少，而且使用Huffman压缩时如果Huffman树过大会导致其编码超过一个字节从而导致压缩的最终结果大于原本的文件大小。

四、项目扩展：

gzip：在LZ77压缩的基础上通过对长度，距离分别统计然后将原字符0-255加上长度范围分成29个区间然后通过范式Huffman压缩，获取其每个结点的编码距离。同时统计距离字然后分为30个区间，然后通过范式Huffman树进行压缩，然后获取每个结点的编码长度。此时Huffman数深度不会超过15层。此时对长度编码距离和距离编码距离同时进行游程编码，再对游程编码的结果，进行Huffman编码此时的Huffman树深度不超过7层，然后在统计每个结点的编码长度，最终得到压缩结果。